{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Conway's Reverse Game of Life 2020.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOxd/VB/DLbuDnWoGRH0Y98",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MihailMV/Various/blob/master/Conway's_Reverse_Game_of_Life_2020.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cb_2EqHirruN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "REt4TFJCOgcp"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DafRxa4GOgfF"
      },
      "source": [
        "CNT_LIFE = 20_000\n",
        "CNT_STEP_LIFE = 15\n",
        "HEIGHT = 25\n",
        "WIDTH = 25\n",
        "\n",
        "BATCH_SIZE = 2_000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PX2fxKGST9YF"
      },
      "source": [
        "import time\n",
        "\n",
        "class Configurations:\n",
        "    def __init__(self):\n",
        "        self.verbose = True\n",
        "        self.verbose_step = 10\n",
        "        self.cnt_epoch = 30\n",
        "        self.device = 'cpu'\n",
        "        self.file_log = 'log.txt'\n",
        "        self.lr = 3e-3\n",
        "        self.scheduler_params = dict(\n",
        "                factor = 0.3\n",
        "                , patience=100\n",
        "                , threshold= 0.006\n",
        "                , verbose=True\n",
        "                )\n",
        "\n",
        "\n",
        "class Ð¡onstructor:\n",
        "    def __init__(self, model, loss, metrics, optimizer, scheduler = None, configurations = None):\n",
        "        self.model = model\n",
        "        self.loss = loss\n",
        "        self.metrics = metrics\n",
        "        self.configurations = configurations\n",
        "        self.optimizer = optimizer(self.model.parameters(), lr = self.configurations.lr)\n",
        "        if scheduler != None:\n",
        "          self.scheduler = scheduler(self.optimizer, **self.configurations.scheduler_params)\n",
        "        self.epoch = 0\n",
        "        self.best_score = None\n",
        "        self.history = {'epoch':[], 'loss':[], 'metrics':{}}\n",
        "        for metric in self.metrics.keys():\n",
        "            self.history['metrics'][metric] = []\n",
        "        \n",
        "        self.loss = self.loss.to(self.configurations.device)\n",
        "        self.model = self.model.to(self.configurations.device)\n",
        "\n",
        "    \n",
        "    def one_epoch(self, dataloader, mode = 'train'):\n",
        "        if mode == 'train':\n",
        "            self.model.train()\n",
        "            self.history['epoch'].append(self.epoch)\n",
        "        else:\n",
        "            self.model.eval()        \n",
        "        str_result = ''\n",
        "        cnt = 0\n",
        "        sum_loss = 0\n",
        "        sum_metrica = {}\n",
        "        for metric in self.metrics.keys():\n",
        "            sum_metrica[metric] = 0\n",
        "        time_start = time.time()        \n",
        "        for step, (features, targets) in enumerate(dataloader):\n",
        "            features = features.to(self.configurations.device, dtype = torch.float32)\n",
        "            targets = targets.to(self.configurations.device, dtype = torch.float32)\n",
        "            self.optimizer.zero_grad()            \n",
        "            cnt += 1\n",
        "            with torch.set_grad_enabled(mode == 'train'):\n",
        "                predictions = self.model(features)\n",
        "                predictions = predictions.to(self.configurations.device, dtype = torch.float32)\n",
        "\n",
        "                #\n",
        "                #predictions = predictions.permute(0, 2, 3, 1)\n",
        "                \n",
        "                #predictions = predictions.resize(predictions.shape[0] * predictions.shape[1] * predictions.shape[2],2)\n",
        "                #predictions = predictions.view(-1, 1)\n",
        "                #targets = targets.view(-1, 1)\n",
        "                #targets = targets.long()\n",
        "                #  \n",
        "\n",
        "                loss = self.loss(predictions, targets)                \n",
        "                if mode == 'train':\n",
        "                    loss.backward()\n",
        "                    self.optimizer.step()\n",
        "                    self.scheduler.step(loss.item())                \n",
        "                sum_loss += loss.item()\n",
        "\n",
        "                for metric in self.metrics.keys():\n",
        "                    sum_metrica[metric] += self.metrics[metric](predictions.data, targets)                \n",
        "                str_result = f'{mode} epoch {self.epoch} '\n",
        "                if step+1 != len(dataloader):\n",
        "                    str_result += f'step {step+1}/{len(dataloader)}'\n",
        "                str_result += f'loss = {(sum_loss/cnt):.3f} '\n",
        "                str_metrics = ''\n",
        "                for metric in self.metrics.keys():\n",
        "                    str_metrics += f'{metric} = {(sum_metrica[metric]/cnt):.3f} '                \n",
        "                \n",
        "                str_result += str_metrics\n",
        "                if self.configurations.verbose and step % self.configurations.verbose_step == 0:\n",
        "                    print(str_result, end='\\r')\n",
        "                \n",
        "                if step+1 == len(dataloader):\n",
        "                    str_result += f'time {(time.time() - time_start):.2f}'\n",
        "                    self.log(str_result)\n",
        "                    self.history['loss'].append(sum_loss/cnt)\n",
        "                    for metric in self.metrics.keys():\n",
        "                        self.history['metrics'][metric].append(sum_metrica[metric]/cnt)        \n",
        "\n",
        "    def fit(self, train_loader, val_loader):\n",
        "        for epoch in range(self.configurations.cnt_epoch):\n",
        "            for mode in ['train','val']:\n",
        "                if mode == 'train':\n",
        "                    dataloader = train_loader\n",
        "                else:\n",
        "                    dataloader = val_loader\n",
        "                self.one_epoch(dataloader, mode)\n",
        "            self.epoch += 1\n",
        "    \n",
        "    def log(self, message):\n",
        "        if self.configurations.verbose:\n",
        "            print(message)\n",
        "        with open(self.configurations.file_log, 'a+') as logger:\n",
        "            logger.write(f'{message}\\n')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7LwRSe0ZU041"
      },
      "source": [
        "class LifeDataset(Dataset):\n",
        "  def __init__(self,x,y):\n",
        "    self.x = x\n",
        "    self.y = y\n",
        "  \n",
        "  def __getitem__(self,id):\n",
        "    return self.x[id], self.y[id]\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VXT5LcnWVQGc"
      },
      "source": [
        "model = torch.nn.Sequential(\n",
        "\n",
        "\n",
        "     nn.Conv2d(in_channels=1, out_channels=32, kernel_size=7, padding=3)\n",
        "    , nn.ReLU()\n",
        "    , nn.BatchNorm2d(32)\n",
        "    , nn.Conv2d(in_channels=32, out_channels=32, kernel_size=5, padding=2)\n",
        "    , nn.ReLU()\n",
        "    , nn.BatchNorm2d(32)\n",
        "    , nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, padding=1)\n",
        "    , nn.ReLU()\n",
        "    , nn.BatchNorm2d(32)\n",
        "\n",
        "    , nn.Conv2d(in_channels=32, out_channels=64, kernel_size=7, padding=3)\n",
        "    , nn.ReLU()\n",
        "    , nn.BatchNorm2d(64)\n",
        "    , nn.Conv2d(in_channels=64, out_channels=64, kernel_size=5, padding=2)\n",
        "    , nn.ReLU()\n",
        "    , nn.BatchNorm2d(64)\n",
        "    , nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1)\n",
        "    , nn.ReLU()\n",
        "    , nn.BatchNorm2d(64)\n",
        "\n",
        "    #, nn.ConvTranspose2d(kernel_size=25, in_channels=128, out_channels=2)\n",
        "    #, nn.ReLU()\n",
        "\n",
        "    , nn.Conv2d(in_channels=64, out_channels=1, kernel_size=1, padding=0)\n",
        "    #, nn.Softmax(dim=1)\n",
        "    , nn.Sigmoid()\n",
        "    )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LKkkeEeWzYM"
      },
      "source": [
        "class Unet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Unet, self).__init__()\n",
        "\n",
        "    self.con11 = nn.Conv2d(kernel_size=3, in_channels=1, out_channels=8, padding=1)\n",
        "    self.r11 = nn.ReLU()\n",
        "    self.batch11 = nn.BatchNorm2d(8)\n",
        "    self.con12 = nn.Conv2d(kernel_size=3, in_channels=8, out_channels=8, padding=1)\n",
        "    self.r12 = nn.ReLU()\n",
        "    self.batch12 = nn.BatchNorm2d(8)\n",
        "    self.max1 = nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "    self.con21 = nn.Conv2d(kernel_size=3, in_channels=8, out_channels=16, padding=1)\n",
        "    self.r21 = nn.ReLU()\n",
        "    self.batch21 = nn.BatchNorm2d(16)\n",
        "    self.con22 = nn.Conv2d(kernel_size=3, in_channels=16, out_channels=16, padding=1)\n",
        "    self.r22 = nn.ReLU()\n",
        "    self.batch22 = nn.BatchNorm2d(16)\n",
        "    self.max2 = nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "    self.con31 = nn.Conv2d(kernel_size=3, in_channels=16, out_channels=32, padding=1)\n",
        "    self.r31 = nn.ReLU()\n",
        "    self.batch31 = nn.BatchNorm2d(32)\n",
        "    self.con32 = nn.Conv2d(kernel_size=3, in_channels=32, out_channels=32, padding=1)\n",
        "    self.r32 = nn.ReLU()\n",
        "    self.batch32 = nn.BatchNorm2d(32)\n",
        "    self.max3 = nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "    self.con = nn.Conv2d(kernel_size=3, in_channels=32, out_channels=64)\n",
        "\n",
        "    self.up41 = nn.ConvTranspose2d(kernel_size=3, in_channels=64, out_channels=32)\n",
        "    self.con41 = nn.Conv2d(kernel_size=3, in_channels=64, out_channels=32, padding=1)\n",
        "    self.r41 = nn.ReLU()\n",
        "    self.batch41 = nn.BatchNorm2d(32)\n",
        "    self.con42 = nn.Conv2d(kernel_size=3, in_channels=32, out_channels=32, padding=1)\n",
        "    self.r42 = nn.ReLU()\n",
        "    self.batch42 = nn.BatchNorm2d(32)\n",
        "\n",
        "    self.up51 = nn.ConvTranspose2d(kernel_size=4, in_channels=32, out_channels=16)\n",
        "    self.con51 = nn.Conv2d(kernel_size=3, in_channels=32, out_channels=16, padding=1)\n",
        "    self.r51 = nn.ReLU()\n",
        "    self.batch51 = nn.BatchNorm2d(16)\n",
        "    self.con52 = nn.Conv2d(kernel_size=3, in_channels=16, out_channels=16, padding=1)\n",
        "    self.r52 = nn.ReLU()\n",
        "    self.batch52 = nn.BatchNorm2d(16)\n",
        "\n",
        "    self.up61 = nn.ConvTranspose2d(kernel_size=2, in_channels=16, out_channels=8, stride= 2)\n",
        "    self.con61 = nn.Conv2d(kernel_size=3, in_channels=16, out_channels=8, padding=1)\n",
        "    self.r61 = nn.ReLU()\n",
        "    self.batch61 = nn.BatchNorm2d(8)\n",
        "    self.con62 = nn.Conv2d(kernel_size=3, in_channels=8, out_channels=8, padding=1)\n",
        "    self.r62 = nn.ReLU()\n",
        "    self.batch62 = nn.BatchNorm2d(8)\n",
        "\n",
        "    self.up = nn.ConvTranspose2d(kernel_size=3, in_channels=8, out_channels=1, stride= 2)\n",
        "    #self.r = nn.Softmax(dim=1)\n",
        "    self.r = nn.Sigmoid()\n",
        "\n",
        "  def forward(self, x):\n",
        "    x1 = self.max1(self.batch12(self.r12(self.con12(self.batch11(self.r11(self.con11(x)))))))\n",
        "    x2 = self.max2(self.batch22(self.r22(self.con22(self.batch21(self.r21(self.con21(x1)))))))\n",
        "    x3 = self.max3(self.batch32(self.r32(self.con32(self.batch31(self.r31(self.con31(x2)))))))\n",
        "    x = self.con(x3)\n",
        "\n",
        "    x = self.up41(x)\n",
        "    x = torch.cat([x,x3], dim=1)\n",
        "    x = self.batch42(self.r42(self.con42(self.batch41(self.r41(self.con41(x))))))\n",
        "\n",
        "    x = self.up51(x)\n",
        "    x = torch.cat([x,x2], dim=1)\n",
        "    x = self.batch52(self.r52(self.con52(self.batch51(self.r51(self.con51(x))))))\n",
        "\n",
        "    x = self.up61(x)\n",
        "    x = torch.cat([x,x1], dim=1)\n",
        "    x = self.batch62(self.r62(self.con62(self.batch61(self.r61(self.con61(x))))))\n",
        "    \n",
        "    x = self.r(self.up(x))\n",
        "\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2IWv6Utkcw65"
      },
      "source": [
        "class LossLife(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(LossLife, self).__init__()\n",
        "\n",
        "    self.nn_step_life = nn.Conv2d(1,1,3,padding=(1,1))\n",
        "    self.nn_step_life.weight.data = self.nn_step_life.weight.data * 0 + 1 \n",
        "    self.nn_step_life.bias.data *= 0\n",
        "    self.nn_step_life.requires_grad = False\n",
        "  \n",
        "  \n",
        "\n",
        "  def forward(self, x, y):\n",
        "    x_new = self.nn_step_life(x)\n",
        "    #x_new = (x == 0) * 1. * (x_new == 3) + (x == 1) * 1. * ((x_new == 2)  + (x_new == 3))\n",
        "    #x_new = x\n",
        "    x = 2**x + 2**(x_new+2)\n",
        "    w = (y * 9) + 1\n",
        "      \n",
        "    return (torch.min(torch.min((x - y * 18.).abs(), (x - y * 33.).abs()), (x - y * 34.).abs()) * w).sum() #(x_new - y).abs().sum()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDaoTcUw7I40"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "omDtNEq3rgKM"
      },
      "source": [
        "#model = Unet()\n",
        "#model = RestNet()\n",
        "\n",
        "#model(x_train).shape\n",
        "#model(x_train[0:1]).shape\n",
        "#model(x_train[0:1]).shape\n",
        "\n",
        "#model(x_train[0:1]).shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jByh8pSuvHlQ"
      },
      "source": [
        "#t = model(x_train[0:2]) #.shape, x_train[0:2].shape\n",
        "#t.min()\n",
        "\n",
        "#n = nn.ConvTranspose2d(1,1,3)\n",
        "#nn.ConvTranspose2d(in_channels=1, out_channels=3, kernel_size=3, padding=1)(x_train[0:1]).shape\n",
        "\n",
        "#n.weight, n.bias\n",
        "\n",
        "#y = model(x_train[0:1])\n",
        "\n",
        "#y.argmax(dim=1) * 1.\n",
        "\n",
        "\n",
        "#y = (model(x_train[0:1])> 0.5) * 1.\n",
        "#y = y.view(-1) #.shape\n",
        "#y.shape\n",
        "#y = y.permute(0, 2, 3, 1).view(-1,2)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cMc6IpwvVLPr"
      },
      "source": [
        "#n(x_train[0:1])\n",
        "#loss(y, y_train[0:1].view(-1))\n",
        "\n",
        "#y.shape, y_train[0:1].view(-1).shape\n",
        "#y.dtype, y_train[0:1].view(-1).dtype\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5Pe13zC5ru4"
      },
      "source": [
        "#loss(y, y_train[0:1].view(-1).long())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-izYbxwOgiT"
      },
      "source": [
        "# ÐÐ¾Ð´ÐµÐ»Ñ Ð´Ð»Ñ ÑÐ°ÑÑÐµÑÐ° Ð¾Ð´Ð½Ð¾Ð³Ð¾ ÑÑÐ°Ð¿Ð° \"Ð¶Ð¸Ð·Ð½Ð¸\"\n",
        "def one_step_life(pitch):\n",
        "  nn_step_life = nn.Conv2d(1,1,3,padding=(1,1))\n",
        "  nn_step_life.weight.data = nn_step_life.weight.data * 0 + 1 \n",
        "  nn_step_life.bias.data *= 0\n",
        "  pitch_new = nn_step_life(pitch)\n",
        "  return (pitch == 0) * 1. * (pitch_new == 3) + (pitch == 1) * 1. * ((pitch_new == 2)  + (pitch_new == 3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wyx0y3HrOgkU"
      },
      "source": [
        "def new_pitchs(cnt_life, height, width):\n",
        "  pitch = torch.rand(cnt_life,1,height, width)\n",
        "  density = (torch.ones(cnt_life,1,height, width).view(cnt_life,-1) * torch.rand(cnt_life).view(cnt_life,-1)).view(cnt_life,1,height, width)\n",
        "  pitch = (pitch > density) * 1.\n",
        "  return pitch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fdymvz5u-c8j"
      },
      "source": [
        "#class BCELoss2d(torch.nn.BCELoss):\n",
        "  #def __init__(self, weight):\n",
        "  #  super().__init__(self, weight)\n",
        "  \n",
        "#  def forward(self, input, target):\n",
        "#    input = input.view(-1)\n",
        "#    target = target.view(-1)\n",
        "#    super().forward(input, target)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ogzgEVIK3VWV"
      },
      "source": [
        "#(x_train == y_train) * 1 / (x_train.shape)\n",
        "#x_train.shape\n",
        "#torch.prod(x_train.shape)\n",
        "\n",
        "#accuracy_score_2d(x_train, y_train)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XyZIXYm83DhP"
      },
      "source": [
        "def accuracy_score_2d(input, target):\n",
        "  #print(input.shape)\n",
        "\n",
        "  #input = input.argmax(dim=1) * 1.\n",
        "  input = (input > 0.5) * 1.\n",
        "  target = (target > 0.5) * 1.  \n",
        "  return 1-  ((input == target) * 1.).sum() / input.shape.numel()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDzPlMPdMS4l"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihFKBkWMMjLR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4-Z0FEhOgnK"
      },
      "source": [
        "pitch = new_pitchs(CNT_LIFE, HEIGHT, WIDTH)\n",
        "\n",
        "for step_life in range(CNT_STEP_LIFE):\n",
        "  pitch_new = one_step_life(pitch)\n",
        "  if step_life == 5:\n",
        "    x_train = pitch_new\n",
        "    y_train = pitch\n",
        "  elif step_life > 5:\n",
        "    x_train = torch.cat((x_train, pitch_new), dim = 0)\n",
        "    y_train = torch.cat((y_train, pitch), dim = 0)\n",
        "  \n",
        "  pitch = pitch_new[(pitch_new.sum(dim=(1,2,3)) > 0) & ((pitch != pitch_new).sum(dim=(1,2,3)) > 0)]\n",
        "\n",
        "del pitch, pitch_new\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H33SnAF74eZk"
      },
      "source": [
        "pitch = new_pitchs(CNT_LIFE, HEIGHT, WIDTH)\n",
        "\n",
        "for step_life in range(CNT_STEP_LIFE):\n",
        "  pitch_new = one_step_life(pitch)\n",
        "  if step_life == 5:\n",
        "    x_val = pitch_new\n",
        "    y_val = pitch\n",
        "  elif step_life > 5:\n",
        "    x_val = torch.cat((x_val, pitch_new), dim = 0)\n",
        "    y_val = torch.cat((y_val, pitch), dim = 0)\n",
        "  \n",
        "  pitch = pitch_new[(pitch_new.sum(dim=(1,2,3)) > 0) & ((pitch != pitch_new).sum(dim=(1,2,3)) > 0)]\n",
        "\n",
        "del pitch, pitch_new\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0a5_VdnCrjj9",
        "outputId": "d4cd5765-2105-4ba4-9a1b-015569d53427",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "x_train.shape, x_val.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([118337, 1, 25, 25]), torch.Size([118766, 1, 25, 25]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l3aptRahx7lI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Us93etYc_KKV"
      },
      "source": [
        "#x_train.to(conf.device)\n",
        "#y_train.to(conf.device)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxZe6O_tOgqF"
      },
      "source": [
        "train_dataset = LifeDataset(x_train, x_train)\n",
        "val_dataset = LifeDataset(x_val, x_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BribDdsgdjp5"
      },
      "source": [
        "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=16)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=16)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UO1mGo8Pah2g"
      },
      "source": [
        "conf = Configurations()\n",
        "conf.device = 'cuda:0'\n",
        "conf.cnt_epoch = 15\n",
        "conf.lr = 3e-3\n",
        "\n",
        "#loss = torch.nn.CrossEntropyLoss(weight=torch.tensor([1.,10.]))\n",
        "loss = torch.nn.BCELoss()\n",
        "#loss = LossLife()\n",
        "\n",
        "metrics = {'acc' :accuracy_score_2d}\n",
        "optimizer = torch.optim.Adam\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau\n",
        "\n",
        "#model.to(conf.device)\n",
        "\n",
        "const = Ð¡onstructor(model, loss, metrics, optimizer, scheduler, conf)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F88OK-f7dkvm",
        "outputId": "4d3da662-bb0f-4c11-fa25-f4cd6f53af14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        }
      },
      "source": [
        "const.fit(train_dataloader, val_dataloader)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train epoch 0 loss = 81796124.500 acc = 0.175 time 50.96\n",
            "val epoch 0 loss = 37059862.317 acc = 0.092 time 13.21\n",
            "train epoch 1 loss = 28269895.854 acc = 0.092 time 52.06\n",
            "val epoch 1 loss = 24117228.333 acc = 0.092 time 13.32\n",
            "train epoch 2 loss = 20569630.242 acc = 0.092 time 53.17\n",
            "val epoch 2 loss = 19444942.317 acc = 0.092 time 13.48\n",
            "train epoch 3 loss = 16432129.883 acc = 0.092 time 53.79\n",
            "val epoch 3 loss = 14244699.517 acc = 0.092 time 13.61\n",
            "train epoch 4 loss = 13484251.629 acc = 0.092 time 53.80\n",
            "val epoch 4 loss = 13524754.158 acc = 0.092 time 13.55\n",
            "train epoch 5 loss = 12661373.800 acc = 0.092 time 53.93\n",
            "val epoch 5 loss = 12303368.717 acc = 0.092 time 13.52\n",
            "train epoch 6 loss = 11963508.835 acc = 0.092 time 53.97\n",
            "val epoch 6 loss = 12363894.917 acc = 0.092 time 13.57\n",
            "train epoch 7 loss = 11501602.575 acc = 0.092 time 53.92\n",
            "val epoch 7 loss = 11796946.642 acc = 0.092 time 13.58\n",
            "train epoch 8 loss = 10990951.304 acc = 0.091 time 53.82\n",
            "val epoch 8 loss = 10761552.542 acc = 0.091 time 13.52\n",
            "train epoch 9 loss = 10542947.119 acc = 0.090 time 54.00\n",
            "val epoch 9 loss = 10599006.446 acc = 0.090 time 13.59\n",
            "train epoch 10 loss = 10206539.904 acc = 0.090 time 53.86\n",
            "val epoch 10 loss = 10066069.383 acc = 0.091 time 13.55\n",
            "train epoch 11 loss = 9902479.921 acc = 0.090 time 53.82\n",
            "val epoch 11 loss = 10085315.254 acc = 0.088 time 13.57\n",
            "train epoch 12 loss = 9709763.400 acc = 0.088 time 53.85\n",
            "val epoch 12 loss = 10057572.258 acc = 0.087 time 13.58\n",
            "Epoch   821: reducing learning rate of group 0 to 9.0000e-04.\n",
            "train epoch 13 loss = 9497403.000 acc = 0.087 time 53.93\n",
            "val epoch 13 loss = 9454959.258 acc = 0.086 time 13.55\n",
            "train epoch 14 loss = 9396269.400 acc = 0.086 time 54.08\n",
            "val epoch 14 loss = 9412650.196 acc = 0.087 time 13.64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDxEHFX6TeDc",
        "outputId": "59115499-40eb-4d3c-f29b-d9f71a92cf06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 635
        }
      },
      "source": [
        "const.fit(train_dataloader, val_dataloader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train epoch 15 loss = 9366723.850 acc = 0.086 time 53.08\n",
            "val epoch 15 loss = 9364175.238 acc = 0.087 time 13.44\n",
            "Epoch  1001: reducing learning rate of group 0 to 2.7000e-04.\n",
            "train epoch 16 loss = 9308424.721 acc = 0.086 time 53.57\n",
            "val epoch 16 loss = 9317549.375 acc = 0.086 time 13.56\n",
            "train epoch 17 loss = 9280736.121 acc = 0.086 time 53.85\n",
            "val epoch 17 loss = 9308583.175 acc = 0.086 time 13.55\n",
            "Epoch  1102: reducing learning rate of group 0 to 8.1000e-05.\n",
            "train epoch 18 loss = 9274921.342 acc = 0.086 time 54.01\n",
            "val epoch 18 loss = 9297186.804 acc = 0.086 time 13.55\n",
            "train epoch 19 loss = 9262666.733 acc = 0.086 time 53.80\n",
            "val epoch 19 loss = 9289038.804 acc = 0.086 time 13.58\n",
            "Epoch  1241: reducing learning rate of group 0 to 2.4300e-05.\n",
            "train epoch 20 loss = 9259044.717 acc = 0.086 time 54.09\n",
            "val epoch 20 loss = 9286656.608 acc = 0.086 time 13.56\n",
            "train epoch 21 loss = 9253114.787 acc = 0.086 time 54.03\n",
            "val epoch 21 loss = 9285472.700 acc = 0.086 time 13.63\n",
            "Epoch  1342: reducing learning rate of group 0 to 7.2900e-06.\n",
            "train epoch 22 loss = 9251589.558 acc = 0.086 time 54.02\n",
            "val epoch 22 loss = 9286588.867 acc = 0.086 time 13.60\n",
            "train epoch 23 loss = 9255876.637 acc = 0.086 time 54.00\n",
            "val epoch 23 loss = 9285266.229 acc = 0.086 time 13.68\n",
            "Epoch  1443: reducing learning rate of group 0 to 2.1870e-06.\n",
            "train epoch 24 loss = 9252715.771 acc = 0.086 time 54.02\n",
            "val epoch 24 loss = 9283998.992 acc = 0.086 time 13.56\n",
            "Epoch  1544: reducing learning rate of group 0 to 6.5610e-07.\n",
            "train epoch 25 loss = 9253358.850 acc = 0.086 time 54.01\n",
            "val epoch 25 loss = 9286666.825 acc = 0.086 time 13.63\n",
            "train epoch 26 loss = 9252232.363 acc = 0.086 time 53.88\n",
            "val epoch 26 loss = 9285122.287 acc = 0.086 time 13.64\n",
            "Epoch  1645: reducing learning rate of group 0 to 1.9683e-07.\n",
            "train epoch 27 loss = 9250104.625 acc = 0.086 time 53.83\n",
            "val epoch 27 loss = 9285696.408 acc = 0.086 time 13.61\n",
            "train epoch 28 loss = 9250418.646 acc = 0.086 time 53.82\n",
            "val epoch 28 loss = 9284501.046 acc = 0.086 time 14.31\n",
            "Epoch  1746: reducing learning rate of group 0 to 5.9049e-08.\n",
            "train epoch 29 loss = 9252958.850 acc = 0.086 time 54.77\n",
            "val epoch 29 loss = 9283749.083 acc = 0.086 time 14.30\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-O-xWrhKUB_7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWmHMVEFeK-l"
      },
      "source": [
        "#loss(x_train, x_train)\n",
        "#loss = loss.to(conf.device)\n",
        "#x_train = x_train[0:2].to(conf.device)\n",
        "#x_train.device\n",
        "\n",
        "\n",
        "#x_train[0:1].permute(0, 2, 3, 1).shape\n",
        "#x_train[0:2].sum((1))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mzlgzZNBdHfn",
        "outputId": "75c7a26f-61dc-4cad-d464-1653c758b594",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 342
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mon Sep 28 01:22:36 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.66       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   85C    P0    32W /  75W |   7225MiB /  7611MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}